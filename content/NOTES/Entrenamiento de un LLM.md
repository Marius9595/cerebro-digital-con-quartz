---
curso: "[[Agents Course]]"
bloque: "U1:  ¿Qué son los LLMs?"
orden: "7"
tags: 
num_veces_leida: 0
---
## ¿Cómo es?
Los [[Modelo de Lenguaje Grande|LLM]]s se entrenan en grandes conjuntos de datos de texto, donde aprenden a predecir la siguiente palabra en una secuencia a través de un objetivo de modelado de lenguaje autocontrolado o enmascarado.

A partir de este aprendizaje no supervisado, el modelo aprende la estructura del lenguaje y **patrones subyacentes en el texto, permitiendo al modelo generalizar a datos no vistos**.

Después de este _pre-entrenamiento_ inicial, los [[Modelo de Lenguaje Grande|LLM]]s pueden ser afinados en un objetivo de aprendizaje supervisado para realizar tareas específicas. Por ejemplo, algunos modelos están entrenados para estructuras conversacionales o uso de herramientas, mientras que otros se centran en clasificación o generación de código.