---
curso: "[[Agents Course]]"
bloque: "U2 Bonus: Â¿QuÃ© es la observabilidad y evaluaciÃ³n de agentes?"
orden: "1"
tags: 
num_veces_leida: 0
---

## Â¿QuÃ© es?

La observabilidad consiste en entender quÃ© estÃ¡ sucediendo dentro de tu [[Agente IA]] mediante el anÃ¡lisis de seÃ±ales externas como registros, mÃ©tricas y rastros. Para los [[Agente IA]], esto significa rastrear acciones, uso de herramientas, llamadas al modelo y respuestas para depurar y mejorar el rendimiento del agente.

## Â¿Por quÃ© es Importante la Observabilidad?

Sin observabilidad, los agentes de IA son â€œcajas negrasâ€. Las herramientas de observabilidad hacen que los agentes sean transparentes, permitiÃ©ndote:

- Entender el intercambio entre costos y precisiÃ³n
- Medir la latencia
- Detectar lenguaje daÃ±ino e inyecciÃ³n de prompts
- Monitorear la retroalimentaciÃ³n del usuario

## ## MÃ©tricas Clave para Monitorear

**Latencia:**Â Â¿Con quÃ© rapidez responde el agente? Los tiempos de espera largos afectan negativamente la experiencia del usuario. Debes medir la latencia para tareas y pasos individuales rastreando las ejecuciones del agente. Por ejemplo, un agente que tarda 20 segundos para todas las llamadas al modelo podrÃ­a acelerarse utilizando un modelo mÃ¡s rÃ¡pido o ejecutando llamadas al modelo en paralelo.

**Costos:**Â Â¿CuÃ¡l es el gasto por ejecuciÃ³n del agente? Los agentes de IA dependen de llamadas a LLM facturadas por token o APIs externas. El uso frecuente de herramientas o mÃºltiples prompts puede aumentar rÃ¡pidamente los costos. Por ejemplo, si un agente llama a un LLM cinco veces para una mejora marginal de calidad, debes evaluar si el costo estÃ¡ justificado o si podrÃ­as reducir el nÃºmero de llamadas o usar un modelo mÃ¡s econÃ³mico. El monitoreo en tiempo real tambiÃ©n puede ayudar a identificar picos inesperados (por ejemplo, errores que causan bucles excesivos de API).

**Errores de Solicitud:**Â Â¿CuÃ¡ntas solicitudes fallÃ³ el agente? Esto puede incluir errores de API o llamadas fallidas a herramientas. Para hacer que tu agente sea mÃ¡s robusto contra estos en producciÃ³n, puedes configurar alternativas o reintentos. Por ejemplo, si el proveedor de LLM A estÃ¡ caÃ­do, cambias al proveedor de LLM B como respaldo.

**RetroalimentaciÃ³n del Usuario:**Â Implementar evaluaciones directas del usuario proporciona informaciÃ³n valiosa. Esto puede incluir calificaciones explÃ­citas (pulgar arriba ğŸ‘/abajo ğŸ‘, 1-5 estrellas â­) o comentarios textuales. La retroalimentaciÃ³n negativa consistente debe alertarte, ya que es una seÃ±al de que el agente no estÃ¡ funcionando como se esperaba.

**RetroalimentaciÃ³n ImplÃ­cita del Usuario:**Â Los comportamientos del usuario proporcionan retroalimentaciÃ³n indirecta incluso sin calificaciones explÃ­citas. Esto puede incluir reformulaciÃ³n inmediata de preguntas, consultas repetidas o hacer clic en un botÃ³n de reintento. Por ejemplo, si ves que los usuarios hacen repetidamente la misma pregunta, esto es una seÃ±al de que el agente no estÃ¡ funcionando como se esperaba.

**PrecisiÃ³n:**Â Â¿Con quÃ© frecuencia produce el agente resultados correctos o deseables? Las definiciones de precisiÃ³n varÃ­an (por ejemplo, correcciÃ³n en la resoluciÃ³n de problemas, precisiÃ³n en la recuperaciÃ³n de informaciÃ³n, satisfacciÃ³n del usuario). El primer paso es definir cÃ³mo se ve el Ã©xito para tu agente. Puedes rastrear la precisiÃ³n mediante verificaciones automatizadas, puntuaciones de evaluaciÃ³n o etiquetas de finalizaciÃ³n de tareas. Por ejemplo, marcar rastros como â€œexitososâ€ o â€œfallidosâ€.

**MÃ©tricas de EvaluaciÃ³n Automatizadas:**Â TambiÃ©n puedes configurar evaluaciones automatizadas. Por ejemplo, puedes usar un LLM para puntuar la salida del agente, por ejemplo, si es Ãºtil, precisa o no. TambiÃ©n hay varias bibliotecas de cÃ³digo abierto que te ayudan a puntuar diferentes aspectos del agente. Por ejemplo,Â [RAGAS](https://docs.ragas.io/)Â para agentes RAG oÂ [LLM Guard](https://llm-guard.com/)Â para detectar lenguaje daÃ±ino o inyecciÃ³n de prompts.

En la prÃ¡ctica, una combinaciÃ³n de estas mÃ©tricas proporciona la mejor cobertura de la salud de un agente de IA. 